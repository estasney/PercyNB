{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Name Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gathering\n",
    "\n",
    "If there is a \"Gold Standard\" for a First Name and Gender dataset it must be the [National data](https://www.ssa.gov/oact/babynames/limits.html) provided by the U.S. Social Security Administration.\n",
    "\n",
    "> All names are from Social Security card applications for births that occurred in the United States after 1879. Note that many people born before 1937 never applied for a Social Security card, so their names are not included in our data. For others who did apply, our records may not show the place of birth, and again their names are not included in our data.\n",
    "All data are from a 100% sample of our records on Social Security card applications as of March 2019.\n",
    "\n",
    "Let's get the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import io\n",
    "import re\n",
    "from zipfile import ZipFile\n",
    "\n",
    "\n",
    "url = \"https://www.ssa.gov/oact/babynames/names.zip\"\n",
    "r = requests.get(url, allow_redirects=True)\n",
    "\n",
    "raw = io.BytesIO(r.content)\n",
    "data = {}\n",
    "\n",
    "with ZipFile(raw) as myzip:\n",
    "    file_names = myzip.namelist()\n",
    "    file_names = filter(lambda x: 'yob' in x, file_names)\n",
    "    for f in file_names:\n",
    "        year_of_birth = int(re.search(r\"[0-9]{4}\", f).group())\n",
    "        with myzip.open(f) as myfile:\n",
    "            data[year_of_birth] = myfile.read().decode().splitlines()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "Since we are interested in aggregating these counts by name across several years let's do so after choosing a range of years.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "name_counts = {}\n",
    "start_year = 1970\n",
    "\n",
    "for year, names in data.items():\n",
    "    if year < start_year:\n",
    "        continue\n",
    "    for line in names:\n",
    "        name, gender, count = line.split(\",\")\n",
    "        count = int(count)\n",
    "        current_counts = name_counts.get(name, {'M': 0, 'F': 0})\n",
    "        current_counts[gender] += count\n",
    "        name_counts[name] = current_counts\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(list(name_counts.items()), columns=['Name', 'Counts'])\n",
    "df = df.join(df['Counts'].apply(pd.Series))\n",
    "del df['Counts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>M</th>\n",
       "      <th>F</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>51915</th>\n",
       "      <td>Rayqwan</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20838</th>\n",
       "      <td>Neshawn</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59181</th>\n",
       "      <td>Zamier</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31805</th>\n",
       "      <td>Starkesha</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72986</th>\n",
       "      <td>Jahiyah</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Name    M   F\n",
       "51915    Rayqwan   11   0\n",
       "20838    Neshawn   64  10\n",
       "59181     Zamier  120   0\n",
       "31805  Starkesha    0  35\n",
       "72986    Jahiyah    0  18"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SSA mentions a point that is of interest to us:\n",
    "> Name data are not edited. For example, the sex associated with a name may be incorrect. Entries such as \"Unknown\" and \"Baby\" are not removed from the lists.\n",
    "\n",
    "We will manually remove these\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Manually removing data that are not 'real' names\n",
    "import numpy as np\n",
    "import operator\n",
    "\n",
    "# Helper functions for chaining multiple filters\n",
    "\n",
    "def make_filter(df, col, value, op):\n",
    "    return op(df[col], value)\n",
    "\n",
    "def combine_filters(df, boolean, *filters):\n",
    "    return df[(boolean(*filters))]\n",
    "\n",
    "def remove_names(names, df=df, col='Name', op=operator.ne):\n",
    "    current_count = len(df)\n",
    "    filters = []\n",
    "    for name in names:\n",
    "        f1 = make_filter(df, col, name, op)\n",
    "        filters.append(f1)\n",
    "        \n",
    "    # np.logical_or.reduce == \"matching any of these conditions\"\n",
    "    # np.logical_and.reduce == \"matching all of these conditions\"\n",
    "    \n",
    "    df1 = combine_filters(df, np.logical_and.reduce, filters)\n",
    "    print(\"Removed {} Names\".format(current_count - len(df1)))\n",
    "    return df1\n",
    "\n",
    "names_to_remove = ['Person', 'Baby', 'Unknown', 'First', 'Firstname', 'First Name', 'Boy', 'Girl',\n",
    "                   'Man', 'Woman']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 5 Names\n"
     ]
    }
   ],
   "source": [
    "df = remove_names(names_to_remove)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Compiling\n",
    "\n",
    "With our collected names and their respective male and female counts we may now proceed to coupling our data with methods that will search for these names and return their counts.   \n",
    "\n",
    "I find that [flashtext](https://github.com/vi3k6i5/flashtext) is well suited for this task. It implements a [Trie Dictionary](https://en.wikipedia.org/wiki/TrieDictionary) which will help overcome the performance bottleneck from searching for this many names.\n",
    "\n",
    "To install flashtext from a notebook\n",
    "```\n",
    "pip! install flashtext\n",
    "```\n",
    "   \n",
    "Let's create and load our data into a `flashtext.keyword.KeywordProcessor` class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from flashtext.keyword import KeywordProcessor\n",
    "kp = KeywordProcessor()\n",
    "for i, row in df.iterrows():\n",
    "    name, n_male, n_female = row['Name'], row['M'], row['F']\n",
    "    kp.add_keyword(name, (n_male, n_female))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Note that we are storing the counts in a tuple so their order matters. Whenever we mention M/F counts, they will always follow the convention of `(n_male, n_female)`\n",
    "\n",
    "Now let's try our new `KeywordProcessor`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "John , n_male : 1218600, n_female: 5448\n",
      "john , n_male : 1218600, n_female: 5448\n",
      "smith, john , n_male : 1218600, n_female: 5448\n",
      "john smith , n_male : 1218600, n_female: 5448\n",
      "John Smith III , n_male : 1218600, n_female: 5448\n"
     ]
    }
   ],
   "source": [
    "test_names = [\"John\", \"john\", \"smith, john\", \"john smith\", \"John Smith III\"]\n",
    "for name in test_names:\n",
    "    result = max(kp.extract_keywords(name), key=lambda x: sum(x))\n",
    "    print(\"{} , n_male : {}, n_female: {}\".format(name, result[0], result[1]))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "As we can see, we are still able to detect \"John\" in the above names and have the counts for \"John\" returned\n",
    "\n",
    "Now we can persist our `KeywordProcessor` with `pickle` so that we may use in future notebooks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(r'data/keyword_processor.pkl', 'wb') as fp:\n",
    "    pickle.dump(kp, fp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
